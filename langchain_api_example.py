#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
LangChain MCPé€‚é…å™¨ç¤ºä¾‹è„šæœ¬ - è¿æ¥common-api-server

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨langchain-mcp-adaptersåº“è¿æ¥MCPæœåŠ¡å™¨ï¼Œ
åŠ è½½å·¥å…·ï¼Œå¹¶ä½¿ç”¨LangChain Agentå¤„ç†ç”¨æˆ·æŸ¥è¯¢ã€‚
"""

import os
import json
import asyncio
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# LangChainæ ¸å¿ƒç»„ä»¶
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import BaseTool
from langchain_core.runnables import RunnablePassthrough

# LangChainç»„ä»¶
from langchain.agents import AgentExecutor
from langchain.agents.format_scratchpad import format_to_openai_function_messages
from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser

# OpenAIé›†æˆ
from langchain_openai import ChatOpenAI

# MCPé€‚é…å™¨
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import convert_mcp_tool_to_langchain_tool

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LangChainMCPAPIExample:
    """
    ä½¿ç”¨LangChainé€‚é…å™¨è¿æ¥common-api-serverçš„ç¤ºä¾‹ç±»
    
    è¿™ä¸ªç±»å±•ç¤ºäº†å¦‚ä½•:
    1. è¿æ¥åˆ°common-api-server MCPæœåŠ¡å™¨
    2. åŠ è½½MCPå·¥å…·
    3. å°†MCPå·¥å…·è½¬æ¢ä¸ºLangChainå·¥å…·
    4. åˆ›å»ºLangChain Agent
    5. å¤„ç†ç”¨æˆ·æŸ¥è¯¢
    """
    
    def __init__(self, config_path: str = "mcp-servers.json"):
        """
        åˆå§‹åŒ–LangChain MCPç¤ºä¾‹
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºmcp-servers.json
        """
        self.config_path = config_path
        self.server_configs = {}
        self.mcp_client = None
        self.tools = []
        self.agent_executor = None
        self.memory = []  # ä¿å­˜å¯¹è¯å†å²
        
    async def load_server_configs(self) -> Dict:
        """
        åŠ è½½æœåŠ¡å™¨é…ç½®
        
        Returns:
            åŒ…å«æœåŠ¡å™¨é…ç½®çš„å­—å…¸
        """
        try:
            config_path = Path(self.config_path)
            if not config_path.exists():
                raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {self.config_path}")
                
            with open(config_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
                # æå–mcpServerséƒ¨åˆ†
                self.server_configs = json_data.get("mcpServers", {})
                logger.info(f"å·²åŠ è½½MCPæœåŠ¡å™¨é…ç½®: {self.config_path}")
                return self.server_configs
        except Exception as e:
            logger.error(f"åŠ è½½æœåŠ¡å™¨é…ç½®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
    
    def setup_agent(self, model_name: str = None, temperature: float = 0, enable_tools: bool = True) -> AgentExecutor:
        """
        è®¾ç½®LangChain Agent
        
        Args:
            model_name: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
            temperature: æ¨¡å‹æ¸©åº¦å‚æ•°
            enable_tools: æ˜¯å¦å¯ç”¨å·¥å…·ï¼Œè®¾ä¸ºFalseæ—¶å°†ä¸ä½¿ç”¨å·¥å…·ï¼ˆçº¯èŠå¤©æ¨¡å¼ï¼‰
            
        Returns:
            é…ç½®å¥½çš„AgentExecutor
        """
        if not self.tools and enable_tools:
            raise ValueError("è¯·å…ˆåŠ è½½å·¥å…·å†è®¾ç½®Agent")
            
        # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
        model_name = model_name or os.getenv("OPENAI_MODEL_NAME", "gpt-4o")
        base_url = os.getenv("OPENAI_BASE_URL")
        api_key = os.getenv("OPENAI_API_KEY")
        
        # åˆ›å»ºLLM
        llm_params = {
            "model": model_name,
            "temperature": temperature,
        }
        
        # å¦‚æœè®¾ç½®äº†base_urlï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
        if base_url:
            llm_params["base_url"] = base_url
            
        # å¦‚æœè®¾ç½®äº†api_keyï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
        if api_key:
            llm_params["api_key"] = api_key
            
        # è¾“å‡ºä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼ˆä¸åŒ…æ‹¬æ•æ„Ÿä¿¡æ¯ï¼‰
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        if base_url:
            logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰APIåœ°å€: {base_url}")
        
        # åˆ›å»ºLLMå®ä¾‹
        llm = ChatOpenAI(**llm_params)
        
        # åˆ›å»ºæç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿåˆ©ç”¨å„ç§APIå·¥å…·å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚
            ä½ å¯ä»¥å¤„ç†æ•°æ®ï¼Œå‘é€è¯·æ±‚ï¼Œç®¡ç†å­—å…¸æ•°æ®å’Œå¤„ç†APIæ–‡æ¡£ç­‰ä»»åŠ¡ã€‚
            è¯·ä»”ç»†åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œé€‰æ‹©æœ€åˆé€‚çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ï¼Œå¹¶å°†ç»“æœä»¥æ¸…æ™°æ˜“æ‡‚çš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·ã€‚
            åœ¨å¤„ç†æ•æ„Ÿä¿¡æ¯æ—¶ï¼Œè¯·æ³¨æ„ä¿å¯†æ€§ã€‚"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # å¦‚æœä¸å¯ç”¨å·¥å…·ï¼Œåˆ™ä½¿ç”¨çº¯èŠå¤©æ¨¡å¼
        if not enable_tools:
            logger.info("å·¥å…·åŠŸèƒ½å·²ç¦ç”¨ï¼Œä½¿ç”¨çº¯èŠå¤©æ¨¡å¼")
            
            # ç®€å•çš„èŠå¤©é“¾
            chat_chain = prompt | llm
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ‰§è¡Œå™¨ï¼Œæ¨¡æ‹ŸAgentExecutorçš„æ¥å£
            class SimpleChatExecutor:
                async def ainvoke(self, inputs):
                    response = await chat_chain.ainvoke(inputs)
                    return {"output": response.content}
            
            self.agent_executor = SimpleChatExecutor()
            logger.info("å·²æˆåŠŸè®¾ç½®çº¯èŠå¤©æ¨¡å¼")
            return self.agent_executor
        
        try:
            # é€‚é…DashScope APIçš„å‡½æ•°æ ¼å¼
            # å°†å·¥å…·å…ƒæ•°æ®è½¬æ¢ä¸ºå…¼å®¹çš„æ ¼å¼
            tools_for_binding = []
            
            logger.info(f"å¼€å§‹å¤„ç† {len(self.tools)} ä¸ªå·¥å…·:")
            
            for i, tool in enumerate(self.tools):
                try:
                    # æ£€æŸ¥å·¥å…·æ˜¯å¦æœ‰metadataå±æ€§
                    if not hasattr(tool, 'metadata') or tool.metadata is None:
                        logger.warning(f"å·¥å…· {i+1}/{len(self.tools)} - ç¼ºå°‘metadataå±æ€§ï¼Œå°è¯•ä»å·¥å…·å¯¹è±¡ä¸­æå–ä¿¡æ¯")
                        # å°è¯•ç›´æ¥ä»å·¥å…·å¯¹è±¡è·å–å¿…è¦ä¿¡æ¯
                        tool_metadata = {
                            "name": getattr(tool, 'name', f"tool_{i}"),
                            "description": getattr(tool, 'description', f"å·¥å…· {i+1}"),
                            "parameters": {
                                "type": "object",
                                "properties": {},
                                "required": []
                            }
                        }
                    else:
                        tool_metadata = tool.metadata
                    
                    logger.info(f"å·¥å…· {i+1}/{len(self.tools)} - å…ƒæ•°æ®: {tool_metadata.get('name', getattr(tool, 'name', f'tool_{i}'))}")
                    
                    # æ„å»ºæ ¼å¼åŒ–çš„å·¥å…·
                    formatted_tool = {
                        "name": tool_metadata.get("name", getattr(tool, 'name', f"tool_{i}")),
                        "description": tool_metadata.get("description", getattr(tool, 'description', "å·¥å…·æè¿°æœªæä¾›")),
                        "parameters": tool_metadata.get("parameters", {
                            "type": "object",
                            "properties": {},
                            "required": []
                        })
                    }
                    
                    # éªŒè¯å¹¶ä¿®æ­£parametersæ ¼å¼ï¼Œç¡®ä¿ç¬¦åˆOpenAPIè§„èŒƒ
                    if not isinstance(formatted_tool["parameters"], dict):
                        logger.warning(f"å·¥å…· {formatted_tool['name']} çš„parametersä¸æ˜¯å­—å…¸ç±»å‹ï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼")
                        formatted_tool["parameters"] = {
                            "type": "object",
                            "properties": {},
                            "required": []
                        }
                    
                    if "properties" not in formatted_tool["parameters"]:
                        logger.warning(f"å·¥å…· {formatted_tool['name']} çš„parametersç¼ºå°‘propertieså­—æ®µï¼Œæ·»åŠ ç©ºproperties")
                        formatted_tool["parameters"]["properties"] = {}
                        
                    if "type" not in formatted_tool["parameters"]:
                        logger.warning(f"å·¥å…· {formatted_tool['name']} çš„parametersç¼ºå°‘typeå­—æ®µï¼Œè®¾ç½®ä¸ºobject")
                        formatted_tool["parameters"]["type"] = "object"
                    
                    tools_for_binding.append(formatted_tool)
                    logger.info(f"å·¥å…· {formatted_tool['name']} æˆåŠŸæ ¼å¼åŒ–")
                except Exception as e:
                    logger.error(f"å¤„ç†å·¥å…· {i+1} æ—¶å‡ºé”™: {str(e)}")
                    logger.error(f"é”™è¯¯è¯¦æƒ…: {repr(e)}")
                    if hasattr(e, '__dict__'):
                        logger.error(f"é”™è¯¯å±æ€§: {e.__dict__}")
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨
            if not tools_for_binding:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·å¯ç”¨äºç»‘å®šï¼Œå°†ä½¿ç”¨ç©ºåˆ—è¡¨")
            else:
                logger.info(f"æˆåŠŸæ ¼å¼åŒ– {len(tools_for_binding)} ä¸ªå·¥å…·")
                
            # ç»‘å®šLLMå’Œå·¥å…·
            agent = (
                {
                    "input": RunnablePassthrough(),
                    "chat_history": lambda _: self.memory,
                    "agent_scratchpad": lambda x: format_to_openai_function_messages(x["intermediate_steps"]),
                }
                | prompt
                | llm.bind(functions=tools_for_binding)
                | OpenAIFunctionsAgentOutputParser()
            )
            
            # åˆ›å»ºAgentæ‰§è¡Œå™¨
            self.agent_executor = AgentExecutor.from_agent_and_tools(
                agent=agent,
                tools=self.tools,
                verbose=True,
            )
            
            logger.info("å·²æˆåŠŸè®¾ç½®Agent")
            return self.agent_executor
            
        except Exception as e:
            logger.error(f"è®¾ç½®Agentæ—¶å‡ºé”™: {str(e)}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {repr(e)}")
            if hasattr(e, '__dict__'):
                logger.error(f"é”™è¯¯å±æ€§: {e.__dict__}")
            raise
    
    async def process_query(self, query: str) -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²
            
        Returns:
            å¤„ç†ç»“æœ
        """
        if not self.agent_executor:
            raise ValueError("è¯·å…ˆè®¾ç½®Agentå†å¤„ç†æŸ¥è¯¢")
            
        # è®°å½•ç”¨æˆ·æ¶ˆæ¯
        self.memory.append(HumanMessage(content=query))
        
        # æ‰§è¡ŒæŸ¥è¯¢
        try:
            result = await self.agent_executor.ainvoke({"input": query})
            response = result["output"]
            
            # è®°å½•AIå›å¤
            self.memory.append(AIMessage(content=response))
            
            return response
        except Exception as e:
            error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    async def direct_call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Any:
        """
        ç›´æ¥è°ƒç”¨æŒ‡å®šçš„å·¥å…·ï¼ˆä¸é€šè¿‡Agentï¼‰
        
        Args:
            tool_name: è¦è°ƒç”¨çš„å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        if not self.tools:
            raise ValueError("è¯·å…ˆåŠ è½½å·¥å…·å†å°è¯•ç›´æ¥è°ƒç”¨")
        
        # æŸ¥æ‰¾æŒ‡å®šçš„å·¥å…·
        tool = next((t for t in self.tools if t.name == tool_name), None)
        if not tool:
            available_tools = ", ".join([t.name for t in self.tools])
            raise ValueError(f"æ‰¾ä¸åˆ°å·¥å…·: {tool_name}ã€‚å¯ç”¨å·¥å…·: {available_tools}")
        
        logger.info(f"ç›´æ¥è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {arguments}")
        
        try:
            # è°ƒç”¨å·¥å…·
            result = await tool.ainvoke(arguments)
            logger.info(f"å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸ")
            return result
        except Exception as e:
            error_msg = f"è°ƒç”¨å·¥å…· {tool_name} æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            raise


async def main():
    """ä¸»å‡½æ•°"""
    # é€šè¿‡ç¯å¢ƒå˜é‡è¯»å–é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = os.getenv("MCP_CONFIG_PATH", "mcp-servers.json")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = LangChainMCPAPIExample(config_path=config_path)
    
    try:
        # åŠ è½½æœåŠ¡å™¨é…ç½®
        await client.load_server_configs()
        
        server_name = os.getenv("MCP_SERVER_NAME", "common-api-server")
        if server_name not in client.server_configs:
            raise ValueError(f"æ‰¾ä¸åˆ°æœåŠ¡å™¨é…ç½®: {server_name}")
            
        server_config = client.server_configs[server_name]
        logger.info(f"æ­£åœ¨è¿æ¥åˆ°MCPæœåŠ¡å™¨: {server_name} ({server_config.get('url', 'URLæœªæŒ‡å®š')})")
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨å¤„ç†è¿æ¥å’Œå…³é—­
        async with MultiServerMCPClient({server_name: server_config}) as mcp_client:
            client.mcp_client = mcp_client
            logger.info(f"å·²æˆåŠŸè¿æ¥åˆ°MCPæœåŠ¡å™¨: {server_name}")
            
            # åŠ è½½MCPå·¥å…· - æ³¨æ„get_tools()ä¸æ˜¯å¼‚æ­¥æ–¹æ³•ï¼Œä¸éœ€è¦await
            client.tools = mcp_client.get_tools()
            logger.info(f"å·²ä»MCPæœåŠ¡å™¨åŠ è½½å·¥å…·: {len(client.tools)}ä¸ªå·¥å…·")
            
            # è¾“å‡ºå·¥å…·åç§°ä»¥ä¾›å‚è€ƒ
            for i, tool in enumerate(client.tools):
                logger.info(f"å·¥å…· {i+1}: {tool.name} - {tool.description[:50]}...")
            
            # æ£€æµ‹æ˜¯å¦ä½¿ç”¨DashScope API
            base_url = os.getenv("OPENAI_BASE_URL", "")
            is_dashscope = "dashscope" in base_url.lower() if base_url else False
            
            # å¦‚æœæ˜¯DashScope APIä¸”å­˜åœ¨å·¥å…·ï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦ç¦ç”¨å·¥å…·
            enable_tools = True
            if is_dashscope and client.tools:
                logger.warning("æ£€æµ‹åˆ°æ‚¨ä½¿ç”¨çš„æ˜¯é˜¿é‡Œäº‘DashScope APIï¼Œè¯¥APIå¯èƒ½ä¸æŸäº›å·¥å…·æ ¼å¼ä¸å…¼å®¹")
                response = input("æ˜¯å¦ç¦ç”¨å·¥å…·ä»¥ä½¿ç”¨çº¯èŠå¤©æ¨¡å¼ï¼Ÿ(y/n): ").strip().lower()
                if response in ["y", "yes"]:
                    enable_tools = False
                    logger.info("å·²ç¦ç”¨å·¥å…·ï¼Œå°†ä½¿ç”¨çº¯èŠå¤©æ¨¡å¼")
                else:
                    logger.info("å°†å°è¯•ä½¿ç”¨å·¥å…·æ¨¡å¼ï¼Œå¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·é‡å¯ç¨‹åºå¹¶é€‰æ‹©ç¦ç”¨å·¥å…·")
            
            # è®¾ç½®Agent
            client.setup_agent(enable_tools=enable_tools)
            
            print("\nğŸ“ MCPå·¥å…·å·²åŠ è½½å®Œæˆï¼Œå¯ä»¥å¼€å§‹å¯¹è¯ï¼ˆè¾“å…¥'é€€å‡º'ç»“æŸï¼‰")
            
            # å¤„ç†ç”¨æˆ·è¾“å…¥
            while True:
                user_input = input("\nğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ")
                if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                    
                print("ğŸ¤” æ­£åœ¨æ€è€ƒ...")
                response = await client.process_query(user_input)
                print(f"\nğŸ¤– {response}")
                
                # ç¤ºä¾‹ï¼šç›´æ¥è°ƒç”¨å·¥å…·çš„ä»£ç ï¼ˆå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰
                # try:
                #     result = await client.direct_call_tool(
                #         "mcp_common_api_server_list_api_names",  # æ›¿æ¢ä¸ºå®é™…çš„å·¥å…·åç§°
                #         {"random_string": ""}  # æ›¿æ¢ä¸ºå®é™…çš„å‚æ•°
                #     )
                #     print(f"ç›´æ¥è°ƒç”¨å·¥å…·ç»“æœ: {result}")
                # except Exception as e:
                #     print(f"ç›´æ¥è°ƒç”¨å·¥å…·å¤±è´¥: {str(e)}")
        
    except Exception as e:
        logger.error(f"è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
        # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šè‡ªåŠ¨å…³é—­è¿æ¥ï¼Œæ— éœ€æ˜¾å¼å…³é—­


if __name__ == "__main__":
    # è¿è¡Œä¸»å‡½æ•°
    asyncio.run(main()) 